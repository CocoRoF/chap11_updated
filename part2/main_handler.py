import re
import streamlit as st
from langsmith import uuid7

from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# custom tools
from src.code_interpreter import CodeInterpreterClient
from tools.code_interpreter import code_interpreter_tool, set_code_interpreter_client
from tools.bigquery import BigQueryClient

from youngjin_langchain_tools import StreamlitLanggraphHandler

###### dotenvì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì‚­ì œí•´ì£¼ì„¸ìš” ######
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    import warnings

    warnings.warn(
        "dotenv not found. Please make sure to set your environment variables manually.",
        ImportWarning,
    )
################################################


@st.cache_data  # ìºì‹œë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
def load_system_prompt(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


def init_page():
    st.set_page_config(page_title="Data Analysis Agent", page_icon="ğŸ¤—")
    st.header("Data Analysis Agent ğŸ¤—", divider="rainbow")
    st.sidebar.title("Options")

    # ë©”ì‹œì§€ ì´ˆê¸°í™” / python runtime ì´ˆê¸°í™”
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        welcome_message = "ì•ˆë…•í•˜ì„¸ìš”! BigQuery ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš” ğŸ¤—"
        st.session_state.messages = [{"role": "assistant", "content": welcome_message}]
        # ëŒ€í™”ê°€ ë¦¬ì…‹ë  ë•Œ Code Interpreterì˜ ì„¸ì…˜ë„ ë‹¤ì‹œ ìƒì„±
        st.session_state.code_interpreter_client = CodeInterpreterClient()
        set_code_interpreter_client(st.session_state.code_interpreter_client)
        st.session_state["checkpointer"] = InMemorySaver()
        st.session_state["thread_id"] = str(uuid7())
        st.session_state.custom_system_prompt = load_system_prompt(
            "./prompt/system_prompt.txt"
        )
        st.session_state.uploaded_files = []


def select_model():
    models = ("GPT-5.2", "Claude Sonnet 4.5", "Gemini 2.5 Flash")
    model = st.sidebar.radio("Choose a model:", models)
    if model == "GPT-5.2":
        return ChatOpenAI(temperature=0, model="gpt-5.2")
    elif model == "Claude Sonnet 4.5":
        return ChatAnthropic(temperature=0, model="claude-sonnet-4-5-20250929")
    elif model == "Gemini 2.5 Flash":
        return ChatGoogleGenerativeAI(temperature=0, model="gemini-2.5-flash")


def create_data_analysis_agent(bq_client):
    tools = [
        bq_client.get_table_info_tool(),
        bq_client.exec_query_tool(),
        code_interpreter_tool,
    ]
    llm = select_model()

    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=st.session_state.custom_system_prompt,
        checkpointer=st.session_state["checkpointer"],
        debug=True,
    )

    return agent


def parse_response(response):
    """
    responseì—ì„œ textì™€ image_pathsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤

    response ì˜ˆì‹œ
    ===
    ë¹„íŠ¸ì½”ì¸ì˜ ì¢…ê°€ ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    <img src="./files/file-s4W0rog1pjneOAtWeq21lbDy.png" alt="Bitcoin Closing Price Chart">

    image_pathë¥¼ ê°€ì ¸ì˜¨ í›„ì—ëŠ” img íƒœê·¸ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤
    """
    # img íƒœê·¸ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
    img_pattern = re.compile(r'<img\s+[^>]*?src="([^"]+)"[^>]*?>')

    # img íƒœê·¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ image_pathsë¥¼ ê°€ì ¸ì˜´
    image_paths = img_pattern.findall(response)

    # img íƒœê·¸ë¥¼ ì‚­ì œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
    text = img_pattern.sub("", response).strip()

    return text, image_paths


def display_content(content):
    text, image_paths = parse_response(content)
    st.write(text)
    for image_path in image_paths:
        st.image(image_path, caption="")


def main():
    init_page()
    bq_client = BigQueryClient(st.session_state.code_interpreter_client)
    data_analysis_agent = create_data_analysis_agent(bq_client)

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            display_content(msg["content"])

    if prompt := st.chat_input(placeholder="ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            handler = StreamlitLanggraphHandler(
                container=st.container(),
                expand_new_thoughts=True,
                max_thought_containers=4,
            )

            response = handler.invoke(
                agent=data_analysis_agent,
                input={"messages": [{"role": "user", "content": prompt}]},
                config={"configurable": {"thread_id": st.session_state["thread_id"]}},
            )

            if response:
                # handlerê°€ ë°˜í™˜í•œ ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ì²˜ë¦¬
                _, image_paths = parse_response(response)
                for image_path in image_paths:
                    st.image(image_path, caption="")
                st.session_state.messages.append(
                    {"role": "assistant", "content": response}
                )


if __name__ == "__main__":
    main()
